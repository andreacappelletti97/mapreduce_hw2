config {
    #CSV output format --> comma separated values
    outputFormat = ",",
    #Verbose execution of the job0
    verbose = true,
    #LogGenerator Pattern to look for
    logMessagePattern = "([a-c][e-g][0-3]|[A-Z][5-9][f-w]){5,15}",
    #Comma separator --> different from outputFormat function
    splitByComma = ",",
    #Space separator
    splitBySpace = " ",
    #File separator for logMessages
    logMessageSeparator = "===!!!==="
    #This job divides and create time intervals
    timeIntervalJob {
    name = "TimeInterval",
    #Input directory on HDFS
    inputDir = "input_dir",
    #Output directory on HDFS
    outputDir = "output_dir/time_interval",
    #Input File
    logFileName = "input.log",
    #Log time windows for the interval definition
    timeWindow = 5000,
    #Regular Expression to detect the log type
    pattern = "(TRACE)|(DEBUG)|(INFO)|(WARN)|(ERROR)|(FATAL)",
    #Dummy start date to do operations between time and milliseconds
    standardDate = "1970-01-01 ",
    #Regular Expression to detect a standard time of logs expressed in HH:MM:SS.mmm
    timePattern = "([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])(:|\\.)\\d{3}",
    #Dummy init of Date zone
    dateZone = "UTC",
    #Date format
    dateFormat = "yyyy-MM-dd HH:mm:ss.SSS"
    },
    #This job finds out the frequency of the logMessagePattern for each log type in each time interval
    job0 {
    name = "job0",
    #Input directory on HDFS
    inputDir = "output_dir/time_interval",
    #Output directory on HDFS
    outputDir = "output_dir/job0",
    #Regular Expression to detect the log type
    pattern = "(TRACE)|(DEBUG)|(INFO)|(WARN)|(ERROR)|(FATAL)",
    #Log message contains regex
    contained = "1,1",
    #Log message not contains regex
    notContained = "1,0"
    },
    #This job finds out the frequency in desc order for each time interval of logMessagePattern in the ERROR log type
    job1{
    name = "job1",
    #Input directory on HDFS
    inputDir = "output_dir/time_interval",
    #Output directory on HDFS
    outputDir = "output_dir/job1",
    #Regular Expression to detect the log type
    pattern = "ERROR",
    },
    #This job sorts the output of the previous job
    sorting{
    name = "Sorting",
    #Input directory on HDFS
    inputDir = "output_dir/job1",
    #Output directory on HDFS
    outputDir = "output_dir/sorting",
    },
    #This job finds finds out the overall frequency of the log types in the log files
    job2{
    name = "job2",
    #Input directory on HDFS
    inputDir = "input_dir",
    #Output directory on HDFS
    outputDir = "output_dir/job2",
    #Regular Expression to detect the log type
    pattern = "(TRACE)|(DEBUG)|(INFO)|(WARN)|(ERROR)|(FATAL)",
    }
    #This job finds out the logMessagePattern longest match per type and printout the entire message length
    job3{
    name = "job3",
    #Input directory on HDFS
    inputDir = "input_dir",
    #Output directory on HDFS
    outputDir = "output_dir/job3",
    #Regular Expression to detect the log type
    pattern = "(TRACE)|(DEBUG)|(INFO)|(WARN)|(ERROR)|(FATAL)",
    }
}